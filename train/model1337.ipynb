{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('interim/x_train.csv')\n",
    "y_train = pd.read_csv('interim/y_train.csv')\n",
    "y_train_month = y_train['target_month']\n",
    "y_train_day = y_train['target_day']\n",
    "x_test = pd.read_csv('interim/x_test.csv')\n",
    "\n",
    "# convert to tensors\n",
    "x_train = torch.tensor(x_train.values, dtype=torch.float)\n",
    "y_train_month = torch.tensor(y_train_month.values, dtype=torch.float)\n",
    "y_train_day = torch.tensor(y_train_day.values, dtype=torch.float)\n",
    "x_test = torch.tensor(x_test.values, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MonthDayDataset(Dataset):\n",
    "    def __init__(self, x, y_month=None, y_day=None):\n",
    "        self.x = x\n",
    "        self.train = y_month is not None and y_day is not None\n",
    "        if self.train:\n",
    "            self.y_month = y_month.reshape(-1, 1)\n",
    "            self.y_day = y_day.reshape(-1, 1)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.train:\n",
    "            return self.x[idx], self.y_month[idx], self.y_day[idx]\n",
    "        else:\n",
    "            return self.x[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "dataset = MonthDayDataset(x_train, y_train_month, y_train_day)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(50, 128)\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.fc3 = nn.Linear(256, 512)\n",
    "        self.fc4 = nn.Linear(512, 256)\n",
    "        self.fc5 = nn.Linear(256, 128)\n",
    "        self.fc6 = nn.Linear(128, 64)\n",
    "        self.fc7 = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc4(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc5(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc6(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.sigmoid(self.fc7(x))\n",
    "        return x\n",
    "\n",
    "month_model = Net()\n",
    "day_model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.nn import BCELoss\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "criterion_month = BCELoss()\n",
    "criterion_day = BCELoss()\n",
    "optimizer_month = Adam(month_model.parameters(), lr=1e-3)\n",
    "optimizer_day = Adam(day_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "scheduler_month = ReduceLROnPlateau(optimizer_month, 'min', patience=5)\n",
    "scheduler_day = ReduceLROnPlateau(optimizer_day, 'min', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "def get_f1_score(y_month, y_day, target_month, target_day):\n",
    "    y_month = (y_month.cpu().detach().numpy() > 0.05).astype(int)\n",
    "    y_day = (y_day.cpu().detach().numpy() > 0.02).astype(int)\n",
    "    target_month = target_month.cpu().detach().numpy()\n",
    "    target_day = target_day.cpu().detach().numpy()\n",
    "    return 0.5 * f1_score(target_month, y_month) + 0.5 * f1_score(target_day, y_day) \n",
    "\n",
    "def train_and_eval(epoch):\n",
    "    month_model.train()\n",
    "    day_model.train()\n",
    "    pbar = tqdm(train_loader)\n",
    "    f1s = []\n",
    "    losses = []\n",
    "    for data, target_month, target_day in pbar:\n",
    "        data, target_month, target_day = data.to(device), target_month.to(device), target_day.to(device)\n",
    "        optimizer_month.zero_grad()\n",
    "        optimizer_day.zero_grad()\n",
    "        output_month = month_model(data)\n",
    "        output_day = day_model(data)\n",
    "        loss_month = criterion_month(output_month, target_month)\n",
    "        loss_day = criterion_day(output_day, target_day)\n",
    "        loss = loss_month + loss_day\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer_month.step()\n",
    "        optimizer_day.step()\n",
    "        f1s.append(get_f1_score(output_month, output_day, target_month, target_day))\n",
    "        pbar.set_description(f'Epoch {epoch} Loss: {np.mean(losses):.5f} F1: {np.mean(f1s):.5f}')\n",
    "\n",
    "    month_model.eval()\n",
    "    day_model.eval()\n",
    "    pbar = tqdm(val_loader)\n",
    "    f1s = []\n",
    "    losses = []\n",
    "    for data, target_month, target_day in pbar:\n",
    "        data, target_month, target_day = data.to(device), target_month.to(device), target_day.to(device)\n",
    "        output_month = month_model(data)\n",
    "        output_day = day_model(data)\n",
    "        loss_month = criterion_month(output_month, target_month)\n",
    "        loss_day = criterion_day(output_day, target_day)\n",
    "        loss = loss_month + loss_day\n",
    "        losses.append(loss.item())\n",
    "        f1s.append(get_f1_score(output_month, output_day, target_month, target_day))\n",
    "        pbar.set_description(f'Validation Epoch {epoch} Loss: {np.mean(losses):.5f} F1: {np.mean(f1s):.5f}')\n",
    "\n",
    "    return np.mean(losses), np.mean(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.24414 F1: 0.12887: 100%|██████████| 2549/2549 [00:47<00:00, 53.43it/s]\n",
      "Validation Epoch 0 Loss: 0.23742 F1: 0.12509: 100%|██████████| 638/638 [00:07<00:00, 81.72it/s]\n",
      "Epoch 1 Loss: 0.24067 F1: 0.13054: 100%|██████████| 2549/2549 [00:49<00:00, 51.96it/s]\n",
      "Validation Epoch 1 Loss: 0.23462 F1: 0.13045: 100%|██████████| 638/638 [00:07<00:00, 81.80it/s]\n",
      "Epoch 2 Loss: 0.23985 F1: 0.13025: 100%|██████████| 2549/2549 [00:48<00:00, 52.43it/s]\n",
      "Validation Epoch 2 Loss: 0.23444 F1: 0.12581: 100%|██████████| 638/638 [00:07<00:00, 84.48it/s]\n",
      "Epoch 3 Loss: 0.23902 F1: 0.13229: 100%|██████████| 2549/2549 [00:45<00:00, 55.74it/s]\n",
      "Validation Epoch 3 Loss: 0.24161 F1: 0.14009: 100%|██████████| 638/638 [00:07<00:00, 87.99it/s] \n",
      "Epoch 4 Loss: 0.23836 F1: 0.13292: 100%|██████████| 2549/2549 [00:46<00:00, 55.38it/s]\n",
      "Validation Epoch 4 Loss: 0.23363 F1: 0.12837: 100%|██████████| 638/638 [00:07<00:00, 83.70it/s]\n",
      "Epoch 5 Loss: 0.23855 F1: 0.13322: 100%|██████████| 2549/2549 [00:46<00:00, 54.99it/s]\n",
      "Validation Epoch 5 Loss: 0.23064 F1: 0.12945: 100%|██████████| 638/638 [00:07<00:00, 84.34it/s] \n",
      "Epoch 6 Loss: 0.23765 F1: 0.13342: 100%|██████████| 2549/2549 [00:46<00:00, 54.46it/s]\n",
      "Validation Epoch 6 Loss: 0.23128 F1: 0.12825: 100%|██████████| 638/638 [00:07<00:00, 84.62it/s]\n",
      "Epoch 7 Loss: 0.23209 F1: 0.13782: 100%|██████████| 2549/2549 [00:46<00:00, 55.15it/s]\n",
      "Validation Epoch 7 Loss: 0.22705 F1: 0.13731: 100%|██████████| 638/638 [00:07<00:00, 81.67it/s]\n",
      "Epoch 8 Loss: 0.23040 F1: 0.13984: 100%|██████████| 2549/2549 [00:46<00:00, 54.38it/s]\n",
      "Validation Epoch 8 Loss: 0.22639 F1: 0.13733: 100%|██████████| 638/638 [00:07<00:00, 81.79it/s]\n",
      "Epoch 9 Loss: 0.22975 F1: 0.14157: 100%|██████████| 2549/2549 [00:47<00:00, 54.12it/s]\n",
      "Validation Epoch 9 Loss: 0.22680 F1: 0.13936: 100%|██████████| 638/638 [00:07<00:00, 80.09it/s]\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "month_model.to(device)\n",
    "day_model.to(device)\n",
    "\n",
    "best_loss = 1e9\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss, f1 = train_and_eval(epoch)\n",
    "    scheduler_month.step(f1)\n",
    "    scheduler_day.step(f1)\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        torch.save(month_model.state_dict(), 'models/month_model.pt')\n",
    "        torch.save(day_model.state_dict(), 'models/day_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_target_path = './prediction/target_predicton_tmp.csv'\n",
    "target_path = './prediction/target_predicton.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 527/527 [00:02<00:00, 236.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33707\n"
     ]
    }
   ],
   "source": [
    "test_dataset = MonthDayDataset(x_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "month_model.eval()\n",
    "day_model.eval()\n",
    "y_month = []\n",
    "y_day = []\n",
    "for data in tqdm(test_loader):\n",
    "    data = data.to(device)\n",
    "    output_month = month_model(data)\n",
    "    output_day = day_model(data)\n",
    "    y_month.append((output_month.cpu().detach().numpy() > 0.05).astype(int))\n",
    "    y_day.append((output_day.cpu().detach().numpy() > 0.02).astype(int))\n",
    "\n",
    "y_month = np.concatenate(y_month).reshape(-1)\n",
    "y_day = np.concatenate(y_day).reshape(-1)\n",
    "\n",
    "for i in range(len(y_month)):\n",
    "    if y_day[i] == 1:\n",
    "        y_month[i] = 1\n",
    "\n",
    "predict_data = pd.read_csv('target/y_predict.csv')\n",
    "preds_df = pd.DataFrame({'target_month': y_month, 'target_day': y_day}, columns=['target_month', 'target_day'])\n",
    "preds_df = pd.concat([predict_data, preds_df], axis=1)\n",
    "preds_df = preds_df.drop('month', axis=1)\n",
    "preds_df = preds_df.sort_values(by=['wagnum'])\n",
    "preds_df.to_csv(target_path, index=False)\n",
    "print(len(preds_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05626477569676727"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metrics_f1 import calc_f1_score\n",
    "calc_f1_score( tmp_target_path, target_path,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
